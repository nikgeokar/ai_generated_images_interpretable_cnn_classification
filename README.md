# AI vs Human Generated Images: Interpretable Binary Classification with Convolutional Networks

## Project Overview

This project aims to classify images as either AI-generated or human-generated using a Convolutional Neural Network (CNN). In addition to achieving high classification accuracy, the project emphasizes interpretability using the Integrated Gradients method. This helps in understanding which parts of the image contribute most to the classification decisions. The project also applies advanced image preprocessing, including wavelet transform-based denoising, to improve performance.

## Dataset

The dataset used for this project is the DALL-E Recognition Dataset, which includes images generated by AI (e.g., DALL-E, MidJourney) and human-generated images.

<div align="center">
  <img src="https://github.com/user-attachments/files/17100767/Random_Images.pdf" alt="1" width="500"/>
</div>

Due to storage limitations, the dataset is not included in this repository. You can download it from Kaggle:

[DALL-E Recognition Dataset](https://www.kaggle.com/datasets/superpotato9/dalle-recognition-dataset/data)

## Image Denoising Theory

In this project, we apply a wavelet-based image denoising technique to improve the classification accuracy between AI-generated and human-generated images. 

The denoising process leverages the **Discrete Wavelet Transform (DWT)** to separate images into different frequency components, allowing the model to focus on key features by reducing noise. This technique is particularly important for distinguishing images with noisy textures, such as those generated by AI models like DALL-E, which may introduce random noise in the generation process.

By reducing image noise, our model can better capture subtle but significant differences between real and synthetic images, ultimately improving classification accuracy.


## Model Architecture

The model is a CNN-based binary classifier comprising four convolutional and max-pooling layers, followed by a fully connected layer and a sigmoid output. The architecture efficiently captures complex image features to distinguish between AI and human-generated images.

Additionally, the model incorporates a wavelet transform for noise reduction to enhance classification performance, particularly in images with noisy backgrounds or textures.

<div align="center">
  <img src="https://github.com/user-attachments/files/17100774/CNN_Architecture.pdf" alt="1" width="500"/>
</div>

## Interpretability

For model interpretability, the Integrated Gradients method from Captum has been implemented. This technique highlights the key regions in images that influence the classifier’s decision, providing transparency in the classification process.

## Dependencies

To set up and run this project, the following packages are required:

- `torch`
- `torchvision`
- `matplotlib`
- `numpy`
- `Pillow`
- `scikit-learn`
- `tqdm`
- `captum`
- `PyWavelets`

## Running the Project

1. **Download and Set up the Dataset**: Download the dataset from Kaggle and place it in the appropriate directory.

2. **Data Preprocessing**: Run the `data_preprocessing.ipynb` notebook to prepare the dataset.

3. **Train the Model**: Use the `train_model.ipynb` notebook to train the CNN model.

4. **Evaluate the Model**: After training, you can run the evaluation notebook to review the model’s performance metrics and visual heatmaps.


